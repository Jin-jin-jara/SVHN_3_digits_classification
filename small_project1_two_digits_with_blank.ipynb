{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small_project1_two_digits_with_blank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8LGMCvKo6ERPKGaFjhtpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jin-jin-jara/Small-Project1---two_digits_with_blank_classification/blob/master/small_project1_two_digits_with_blank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdmADYlaH2NI",
        "colab_type": "text"
      },
      "source": [
        "# small project - two digits with blank classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBIQNeIP5Jax",
        "colab_type": "code",
        "outputId": "117abdeb-0a0d-4fc7-d1b2-0e9cc0cae6ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# tensorflow 버전 2를 사용합니다.\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "# 모델을 만들기 위한 라이브러리\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, LSTM, Reshape, Activation, Dropout\n",
        "from tensorflow.keras import Model\n",
        "from keras import optimizers\n",
        "\n",
        "# 데이터 가공과 시각화를 위한 라이브러리\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_0EYmw95V7M",
        "colab_type": "code",
        "outputId": "0cfb9ab1-48ab-42e8-9893-8f56174ffbd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 이번 프로젝트에서 사용할 데이터셋\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "x, y = load_digits(return_X_y=True)\n",
        "\n",
        "# 1797개의 8*8 이미지들. 각 이미지들은 0~9까지의 숫자입니다.\n",
        "x.shape, y.shape, set(y)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1797, 64), (1797,), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7jYu_5COdCX",
        "colab_type": "text"
      },
      "source": [
        "데이터를 train 셋과 test셋을 나눕니다. train 셋과 test셋을 또 절반으로 나눠 좌우로 붙일 것이기 때문에 짝수개의 이미지가 필요합니다.하지만 전체 데이터는 홀수개이기 때문에 마지막 한 개는 사용하지 않겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04PE9ia_5eai",
        "colab_type": "code",
        "outputId": "49f0540b-9696-4d07-f2fc-0e808ffb61ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "m = len(x)//2\n",
        "x_train = x[:m]\n",
        "y_train = y[:m]\n",
        "x_test = x[m:m*2]\n",
        "y_test = y[m:m*2]\n",
        "\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((898, 64), (898, 64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5ezkIMuO2Ct",
        "colab_type": "text"
      },
      "source": [
        "데이터를 반으로 나누고 좌우로 붙이는 함수입니다. 오른쪽 이미지에는 빈 이미지도 추가합니다. 정답인 label 또한 비슷한 작업을 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJK1ZnCH7moP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_2_num(x_data, y_data):\n",
        "  x_data = np.reshape(x_data, [-1, 8, 8])\n",
        "  x_data_l, x_data_r = np.split(x_data, 2, axis=0)\n",
        "  x_data_lr = np.concatenate((x_data_l, x_data_r), axis=2)\n",
        "  y_data_l, y_data_r = np.split(y_data, 2, axis=0)\n",
        "  y_data = np.stack((y_data_l, y_data_r), -1)\n",
        "\n",
        "  BLANK = 10  # 없음을 뜻하는 기호\n",
        "\n",
        "  x_data_blank = np.concatenate((x_data_l, np.zeros_like(x_data_r)), axis=2)\n",
        "  y_data_blank = np.stack((y_data_l, np.zeros_like(y_data_l)+BLANK), 1)\n",
        "\n",
        "  x_data_set = np.concatenate((x_data_lr, x_data_blank), 0)\n",
        "  y_data_set = np.concatenate((y_data, y_data_blank), 0)\n",
        "\n",
        "  return x_data_set, y_data_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhGyNKznGuns",
        "colab_type": "text"
      },
      "source": [
        "각 이미지당 8x16 픽셀의 데이터가 만들어졌습니다. train, test 각각 898개의 이미지를 갖고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH2f7Hyj-4iq",
        "colab_type": "code",
        "outputId": "ad02cae5-9a9a-48dc-8a87-b62e703f4c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_set, y_train_set = convert_2_num(x_train, y_train)\n",
        "x_test_set, y_test_set = convert_2_num(x_test, y_test)\n",
        "x_train_set.shape, x_test_set.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((898, 8, 16), (898, 8, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkIkx8AgHE9V",
        "colab_type": "text"
      },
      "source": [
        "만든 숫자 이미지가 좌우에 잘 붙었나 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hARqtgYAGUTq",
        "colab_type": "code",
        "outputId": "51b671e8-69c9-4ebe-b99e-74e5d8e36d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "i = 100\n",
        "plt.title(\"y:\"+str(y_train_set[i]))\n",
        "plt.imshow(x_train_set[i])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f53578e5ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAADWCAYAAAD4p8hZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAPtUlEQVR4nO3de7BV5X3G8eeRqweIGjFGQcRUpRKT\niMMQrYlppFpMUNJpMtERx1tKp81FM6aO2knUTtvYNGMkU8eMRSOJRGNR1HG8wBAjdaJERDRyM2gM\ngghaowIxIPjrH3sRj4e9z1lH37XXe3K+n5k97Nv58QBnP2ex9lr7dUQIAJCvPeoOAADoHkUNAJmj\nqAEgcxQ1AGSOogaAzFHUAJA5ihp/Umw/Z/sN2z+uYPYQ21tsv2n7X1PPB1qhqPGn6JSIOLPrnbY/\nZTu6K1nblxdFvKXT5UOSFBHbImK4pDkVZgd2Q1GjX7A9SNJMSYtLPP2nETG80+XZiuMB3aKokTXb\n/2T7ti73fd/2zF6OulDSfEmrkoUD2oSiRu5ukjTF9t6SZHugpNMk/ai4fbHtu7sbYPtgSedK+peS\nv+cptl+xvdz2P7z76EAaFDWyFhEbJC2S9IXirimSXo6Ix4rHr4yIqT2M+b6kb0bElhK/5a2SjpC0\nn6S/k/Qt26e/q/BAIhQ1+oLZkqYX16dLKn1Eh+1TJI2IiJ+WeX5ErIiIFyJiZ0T8Qo392p/vbWAg\npYF1BwBKuEPStbaPlDRV0kW9+NrJkibafrG4vZeknbY/EhHTSnx9SHKv0gKJsUWN7EXEHyTNlfQT\nSb+MiLW9+PJvSjpc0lHF5S5J/y3pnGZPtj3N9j5umCTpa5LufC/5gfeKokZfMVvSR9Rlt4ftS23f\n2+qLImJzRLy46yLpDUlbI+KVFl9ymqQ1kjar8Yblf0TE7CR/AuBdMgsHoC+wPUaNQ+s+GBGvd/O8\n1ZIOkDQvIs5KnGGIpI2SBkn6TkRckXI+0ApFjezZ3kPSVZLeFxHn1p0HaDfeTETWbA9TYyv2t2oc\nmgf0O2xRA0DmeDMRADJXya6PwR4SQzWsitHZ89AhyWcO/9AbyWduXsHP6JxtG9uRfujO9IeDjxiW\n/ntzyB47ks/c8vTg5DNjR9qcf9BWbY9tTf+RKinqoRqmj3tyFaOzN+DQcclnfuLmZclnPvjRPZPP\nRDpPXzYx+cw9Xkv/cj/+2OXJZx7WsSn5zIdOPDj5zJ0b0+ZcHAtbPsZmFQBkjqIGgMxR1ACQOYoa\nADJHUQNA5ihqAMhcqaK2PcX2attrbF9cdSgAwNt6LGrbAyRdI+lkSeMlnW57fNXBAAANZbaoJ0la\nExHPRsR2SbdIKrMyBgAggTJFPUrS851uryvuewfbM2wvsb3kTW1LlQ8A+r1kbyZGxHURMTEiJg5S\n+s+7AID+qkxRr5d0UKfbo4v7AABtUKaoH5V0mO1DbA9WY025u6qNBQDYpceP04qIHba/Iul+SQMk\n3RAR6T8yCwDQVKnPPYyIeyTdU3EWAEATnJkIAJmjqAEgcxQ1AGSOogaAzFWyZmJ/tvpL+ySfefVe\nS5PPfFDHJZ/ZX731qQnJZ94/eWbymSfffmHymct/cGTymWteeyv5zI6Ni5PPbCe2qAEgcxQ1AGSO\nogaAzFHUAJA5ihoAMkdRA0DmKGoAyFyZNRNvsL3J9lPtCAQAeKcyW9Q3SppScQ4AQAs9FnVELJL0\nShuyAACaSHYKue0ZkmZI0lB1pBoLAP0ei9sCQOY46gMAMkdRA0Dmyhyed7OkhyWNs73O9nnVxwIA\n7FJmFfLT2xEEANAcuz4AIHMUNQBkjqIGgMxR1ACQuX69uO3vzj42+cxnvnht8pmTLv1G8pkjP5z+\nUwF2Ll+dfGZfsOnoPZPP/OuF5yefecSs3yWfuf6kfZPPHPnoq8ln7kw+sb3YogaAzFHUAJA5ihoA\nMkdRA0DmKGoAyBxFDQCZo6gBIHNlPj3vINsP2F5he7nt9Ad4AgBaKnPCyw5JF0bEUtsjJD1me0FE\nrKg4GwBA5Ra33RARS4vrmyWtlDSq6mAAgIZenUJue6ykCZIWN3mMxW0BoAKl30y0PVzSbZIuiIjX\nuz7O4rYAUI1SRW17kBolPScibq82EgCgszJHfVjS9ZJWRsRV1UcCAHRWZov6OElnSjrB9rLi8pmK\ncwEACmUWt31IktuQBQDQBGcmAkDmKGoAyBxFDQCZo6gBIHP9enHbm674bvKZ56ydknzmyHufST7z\nnsfnJ5/5yS//ffKZHfN2Owm2X/jNlFnJZ97xyeHJZ379f09LPvOL5yxLPvPey/4y+cx2fm+yRQ0A\nmaOoASBzFDUAZI6iBoDMUdQAkDmKGgAyV+bT84ba/qXtJ4o1E69oRzAAQEOZ46i3STohIrYUn0v9\nkO17I+KRirMBAFTu0/NC0pbi5qDiElWGAgC8rewKLwNsL5O0SdKCiOifp4sBQA1KFXVE7IyIoySN\nljTJ9pFdn2N7hu0ltpe8qW2pcwJAv9Wroz4i4lVJD0ja7QMtWNwWAKpR5qiP/WzvXVzfU9KJklZV\nHQwA0FDmqI8DJM22PUCNYr81Iu6uNhYAYJcyR308KWlCG7IAAJrgzEQAyBxFDQCZo6gBIHMUNQBk\njqIGgMz1mcVtf/83H08+8/BB6RfR3Hjegclnrvz2iOQzq/DC8U4+89B5yUcmN2r+/yWfecRe/5h8\n5pjLf5F85uFaknzmjy+fnHzm9uPfSj6znd+bbFEDQOYoagDIHEUNAJmjqAEgcxQ1AGSOogaAzJUu\n6mKVl8dt88l5ANBGvdmiPl/SyqqCAACaK7tm4mhJn5U0q9o4AICuym5RXy3pIknpT+8BAHSrzFJc\nUyVtiojHengei9sCQAXKbFEfJ+lU289JukXSCbZv6vokFrcFgGr0WNQRcUlEjI6IsZJOk/SziJhe\neTIAgCSOowaA7PXqY04j4ueSfl5JEgBAU2xRA0DmKGoAyBxFDQCZo6gBIHMUNQBkrs8sbtsxb3Hy\nmR+efkbymf92x53JZ35u2JbkM6tw4KKoO0Itdi5fnXzmmOXJR/ZrQ8dsrjvCe8IWNQBkjqIGgMxR\n1ACQOYoaADJHUQNA5ihqAMhcqcPzis+i3ixpp6QdETGxylAAgLf15jjqT0fEy5UlAQA0xa4PAMhc\n2aIOSfNtP2Z7RrMnsGYiAFSj7K6PT0TEetsfkLTA9qqIWNT5CRFxnaTrJOl9fn//PJcYACpQaos6\nItYXv26SNE/SpCpDAQDe1mNR2x5me8Su65JOkvRU1cEAAA1ldn3sL2me7V3P/0lE3FdpKgDAH/VY\n1BHxrKSPtSELAKAJDs8DgMxR1ACQOYoaADJHUQNA5ihqAMhcn1nctgqj/zb9CqLX6tDkM1c8+Uby\nmdcv/HTymYfOeyT5zP5qzfeOST5z3yecfOa2fdLP/PYZP0o+85ovfSH5zHZiixoAMkdRA0DmKGoA\nyBxFDQCZo6gBIHMUNQBkrlRR297b9lzbq2yvtH1s1cEAAA1lj6OeKem+iPi87cGSOirMBADopMei\ntr2XpOMlnS1JEbFd0vZqYwEAdimz6+MQSS9J+qHtx23PKlZ6eQcWtwWAapQp6oGSjpZ0bURMkLRV\n0sVdnxQR10XExIiYOEhDEscEgP6rTFGvk7QuIhYXt+eqUdwAgDbosagj4kVJz9seV9w1WdKKSlMB\nAP6o7FEfX5U0pzji41lJ51QXCQDQWamijohlkiZWnAUA0ARnJgJA5ihqAMgcRQ0AmaOoASBzFDUA\nZK5fL27bnw1fy8/onA0dszn5zEun3pl85vjBG5PPnH7ZN5LP3OfBh5PPbCderQCQOYoaADJHUQNA\n5ihqAMgcRQ0AmaOoASBzPRa17XG2l3W6vG77gnaEAwCUOI46IlZLOkqSbA+QtF7SvIpzAQAKvd31\nMVnSMxHx2yrCAAB219szE0+TdHOzB2zPkDRDkoaq4z3GAgDsUnqLuljd5VRJ/9PscRa3BYBq9GbX\nx8mSlkZE+pP7AQAt9aaoT1eL3R4AgOqUKmrbwySdKOn2auMAALoqu7jtVkn7VpwFANAEZyYCQOYo\nagDIHEUNAJmjqAEgcxQ1AGTOEZF+qP2SpDKfBzJS0svJA6RHzrT6Qs6+kFEiZ2p15jw4IvZr9kAl\nRV2W7SURMbG2ACWRM62+kLMvZJTImVquOdn1AQCZo6gBIHN1F/V1Nf/+ZZEzrb6Qsy9klMiZWpY5\na91HDQDoWd1b1ACAHlDUAJC52ora9hTbq22vsX1xXTlasX2Q7Qdsr7C93Pb5dWfqju0Bth+3fXfd\nWVqxvbftubZX2V5p+9i6MzVj++vFv/lTtm+2PbTuTJJk+wbbm2w/1em+99teYPvXxa/71JmxyNQs\n538W/+5P2p5ne+86MxaZdsvZ6bELbYftkXVk66qWoi5WM79GjVVjxks63fb4OrJ0Y4ekCyNivKRj\nJH05w4ydnS9pZd0hejBT0n0R8eeSPqYM89oeJelrkiZGxJGSBqixVmgObpQ0pct9F0taGBGHSVpY\n3K7bjdo95wJJR0bERyU9LemSdodq4kbtnlO2D5J0kqS17Q7USl1b1JMkrYmIZyNiu6RbJE2rKUtT\nEbEhIpYW1zerUSqj6k3VnO3Rkj4raVbdWVqxvZek4yVdL0kRsT0iXq03VUsDJe1pe6CkDkkv1JxH\nkhQRiyS90uXuaZJmF9dnS/pcW0M10SxnRMyPiB3FzUckjW57sC5a/H1K0vckXSQpmyMt6irqUZKe\n73R7nTItQUmyPVbSBEmL603S0tVqfGO9VXeQbhwi6SVJPyx20cwqVg7KSkSsl/RdNbamNkh6LSLm\n15uqW/tHxIbi+ouS9q8zTEnnSrq37hDN2J4maX1EPFF3ls54M7EHtodLuk3SBRHxet15urI9VdKm\niHis7iw9GCjpaEnXRsQESVuVx3/T36HYxztNjR8sB0oaZnt6vanKicaxttlsBTZj+5/V2K04p+4s\nXdnukHSppG/VnaWruop6vaSDOt0eXdyXFduD1CjpORGR63qRx0k61fZzauxCOsH2TfVGamqdpHUR\nset/JXPVKO7c/JWk30TESxHxphrrhP5FzZm6s9H2AZJU/Lqp5jwt2T5b0lRJZ0SeJ3D8mRo/oJ8o\nXk+jJS21/cFaU6m+on5U0mG2D7E9WI03a+6qKUtTtq3G/tSVEXFV3XlaiYhLImJ0RIxV4+/xZxGR\n3RZgRLwo6Xnb44q7JktaUWOkVtZKOsZ2R/E9MFkZvunZyV2SziqunyXpzhqztGR7ihq7506NiN/X\nnaeZiPhVRHwgIsYWr6d1ko4uvndrVUtRF28qfEXS/Wq8CG6NiOV1ZOnGcZLOVGMLdVlx+Uzdofq4\nr0qaY/tJSUdJ+vea8+ym2OKfK2mppF+p8RrJ4rRi2zdLeljSONvrbJ8n6UpJJ9r+tRr/G7iyzoxS\ny5z/JWmEpAXFa+kHtYZUy5xZ4hRyAMgcbyYCQOYoagDIHEUNAJmjqAEgcxQ1AGSOogaAzFHUAJC5\n/wcSOCzUzszL8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6a-x1zjHRvF",
        "colab_type": "code",
        "outputId": "f6105734-d88a-4d44-f57e-7c01a84f1656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "i = 800\n",
        "plt.title(\"y:\"+str(y_train_set[i]))\n",
        "plt.imshow(x_train_set[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f53577b3be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAADWCAYAAAD4p8hZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLGpJapxFLUmNs6glqXH/D6G6A4jYgyE6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNHTGfUhHbg9",
        "colab_type": "text"
      },
      "source": [
        "숫자가 양 옆으로 잘 붙었습니다. 숫자 이미지와 한쪽이 빈 공간인 데이터도 잘 출력됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS1EXnRbINvc",
        "colab_type": "text"
      },
      "source": [
        "CNN모델은 4차원(데이터수(m), 너비(w), 높이(h), 채널(c))의 데이터를 입력으로 받습니다. 하지만 만들어진 데이터셋은 (데이터수, 너비, 높이)만 있으므로 채널 차원을 추가해줍니다. 채널은 1로 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-ZfYGm1H8uX",
        "colab_type": "code",
        "outputId": "35bbeb09-3ad9-411c-f318-df3cb168d6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_set = x_train_set[..., tf.newaxis]\n",
        "x_test_set = x_test_set[..., tf.newaxis]\n",
        "x_train_set.shape, x_test_set.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((898, 8, 16, 1), (898, 8, 16, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4XbDa8TgWSO",
        "colab_type": "code",
        "outputId": "5efc7374-f378-40d8-841b-1e6ddb9af328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_set.shape, x_test_set.shape, y_train_set.shape, y_test_set.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((898, 8, 16, 1), (898, 8, 16, 1), (898, 2), (898, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLX17_GPJGL_",
        "colab_type": "text"
      },
      "source": [
        "배치 사이즈를 정하고 데이터를 데이터 소스로 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wxYci0gIkxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train_set, y_train_set)).shuffle(10000).batch(BATCH_SIZE)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test_set, y_test_set)).shuffle(10000).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxg7pw-5V2a1",
        "colab_type": "text"
      },
      "source": [
        "## Sequential을 이용한 CNN 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maWt_dAnU2bX",
        "colab_type": "text"
      },
      "source": [
        "첫 번째 모델은 keras의 Sequential을 사용해 만들어보겠습니다. keras에서 제공하는 Sequential 모델로 딥러닝 네트워크를 아주 쉽게 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6wP2RoczDh-",
        "colab_type": "code",
        "outputId": "08fe85fa-699e-46c5-a812-e39187138e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(Conv2D(32, 3, padding=\"same\", input_shape=(8, 16, 1)))\n",
        "  model.add(MaxPool2D(2, padding=\"same\"))\n",
        "  model.add(Conv2D(32, 3, padding=\"same\"))\n",
        "  model.add(MaxPool2D(2, padding=\"same\"))\n",
        "  model.add(Conv2D(32, 3, padding=\"same\"))\n",
        "  model.add(MaxPool2D(2, padding=\"same\"))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(22))\n",
        "  model.add(Reshape((2, 11)))  # (m, 2, 11)\n",
        "  model.add(Activation('softmax'))\n",
        "  adam = tf.keras.optimizers.Adam(lr = 0.001)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 8, 16, 32)         320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 4, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 2, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 4, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 1, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 22)                1430      \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 2, 11)             0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 11)             0         \n",
            "=================================================================\n",
            "Total params: 24,406\n",
            "Trainable params: 24,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beSv-XuM5BOu",
        "colab_type": "code",
        "outputId": "462ee884-4954-4a78-af16-d60b0d1f817c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.fit(x_train_set, y_train_set, batch_size = 32, epochs=100, validation_split=0.3,shuffle=True, verbose=0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f532810fd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bVQquanFyqX",
        "colab_type": "code",
        "outputId": "a87d6762-1291-4638-ac20-247649d89907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "loss_metrics = model.evaluate(x_test_set, y_test_set,batch_size=32)\n",
        "print('evaluation loss and_metrics')\n",
        "print(loss_metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898/898 [==============================] - 0s 79us/sample - loss: 0.3431 - accuracy: 0.9271\n",
            "evaluation loss and_metrics\n",
            "[0.34310407153229494, 0.9270601]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CC7H04ZZRtP",
        "colab_type": "text"
      },
      "source": [
        "train 셋에 대한 정확도는 거의 100%에 가깝고 test 셋의 정확도는 92.7%가 나옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJe-LxdtKN42",
        "colab_type": "text"
      },
      "source": [
        "## 텐서플로 2.0 시작하기: 전문가용\n",
        "이번에는 직접 모델을 설계해보겠습니다. 이 모델은 tensorflow 홈페이지의 전문가용 코드를 참고해 만들었습니다. (https://www.tensorflow.org/tutorials/quickstart/advanced?hl=ko)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leG7ZUSIVlc1",
        "colab_type": "text"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q1sncqMGm1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model): \n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.k = 11     # 클래스 개수 (0 ~ 10까지, 10은 빈 이미지를 뜻함)\n",
        "    self.seq = 2     # 자리수 (오른쪽, 왼쪽 두 자리를 예측해야함)\n",
        "    self.conv1 = Conv2D(32, 3, padding=\"same\")\n",
        "    self.pool1 = MaxPool2D(2, padding=\"same\")\n",
        "    self.conv2 = Conv2D(32, 3, padding='same')\n",
        "    self.pool2 = MaxPool2D(2, padding=\"same\")\n",
        "    self.conv3 = Conv2D(32, 3, padding='same')\n",
        "    self.pool3 = MaxPool2D(2, padding=\"same\")\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation=\"relu\")\n",
        "    self.d2 = Dense(self.k*self.seq)   # 22\n",
        "\n",
        "  def call(self, x):\n",
        "    # (m, 8, 16, 1)\n",
        "    x = self.conv1(x) \n",
        "    x = self.pool1(x)  # (m, 4, 8, 32)\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool2(x)  # (m, 2, 4, 32)\n",
        "    x = self.conv3(x)\n",
        "    x = self.pool3(x)  # (m, 1, 2, 32)\n",
        "    x = self.flatten(x)  # (m, 64)\n",
        "    x = self.d1(x)   # (m, 128)\n",
        "    h = self.d2(x)  # (m, 22)\n",
        "    # 두 자리 숫자 [0~10, 0~10]에 대한 예측을 진행해야 하므로 reshape해줍니다.\n",
        "    h = tf.reshape(h, [-1, self.seq, self.k]) # (m, 2, 11)\n",
        "    h = tf.nn.softmax(h, axis=2)   \n",
        "    return h\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrjJ63iDQo3l",
        "colab_type": "text"
      },
      "source": [
        "loss function, optimizer, metrics를 설정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9WAvWbDKU-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 분류에 관한 문제이기 때문에 cross entropy함수를 비용 함수로 사용합니다.\n",
        "# label을 one-hot encoding 했기 때문에 SparseCategoricalCrossentropy 함수가 아닌 CategoricalCrossentropy 함수를 사용합니다.\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"train_acc\")\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"test_acc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkGahwBZQ4zP",
        "colab_type": "text"
      },
      "source": [
        "train과 test를 위한 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keoCsF2HcLOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  y_hot = tf.one_hot(labels, depth=11, axis=-1)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images) # (m, 8, 16, 1)\n",
        "    loss = loss_object(y_hot, predictions)\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(y_hot, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51BZ_6zhdGuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  y_hot = tf.one_hot(labels, depth=11, axis=-1)\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(y_hot, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(y_hot, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1yyG7imeczb",
        "colab_type": "code",
        "outputId": "f156d4d6-fa4d-45af-bad7-113da9f7cfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "EPOCHS = 800\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds: # batch size = 32씩 나눠져 들어갑니다\n",
        "    train_step(images, labels)\n",
        "  \n",
        "  for test_images, labels in test_ds:\n",
        "    test_step(test_images, labels)\n",
        "  \n",
        "  template = \"에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}\"\n",
        "  \n",
        "  if epoch%40==0:\n",
        "    print(template.format(epoch,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result()*100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "에포크: 0, 손실: 1.8129262924194336, 정확도: 39.587974548339844, 테스트 손실: 1.4180071353912354, 테스트 정확도: 56.2917594909668\n",
            "에포크: 40, 손실: 0.0986887514591217, 정확도: 97.044921875, 테스트 손실: 0.3657163381576538, 테스트 정확도: 90.64452362060547\n",
            "에포크: 80, 손실: 0.050039589405059814, 정확도: 98.50421905517578, 테스트 손실: 0.358181893825531, 테스트 정확도: 91.83782958984375\n",
            "에포크: 120, 손실: 0.03351296856999397, 정확도: 98.99869537353516, 테스트 손실: 0.3692639470100403, 테스트 정확도: 92.25689697265625\n",
            "에포크: 160, 손실: 0.02519114315509796, 정확도: 99.24746704101562, 테스트 손실: 0.3803045451641083, 테스트 정확도: 92.4874496459961\n",
            "에포크: 200, 손실: 0.020179588347673416, 정확도: 99.39722442626953, 테스트 손실: 0.39208778738975525, 테스트 정확도: 92.62484741210938\n",
            "에포크: 240, 손실: 0.016830766573548317, 정확도: 99.49726867675781, 테스트 손실: 0.4028720259666443, 테스트 정확도: 92.73211669921875\n",
            "에포크: 280, 손실: 0.014434941112995148, 정확도: 99.56883239746094, 테스트 손실: 0.4150567352771759, 테스트 정확도: 92.82569122314453\n",
            "에포크: 320, 손실: 0.012636194005608559, 정확도: 99.62255859375, 테스트 손실: 0.42591211199760437, 테스트 정확도: 92.89854431152344\n",
            "에포크: 360, 손실: 0.01123606227338314, 정확도: 99.66438293457031, 테스트 손실: 0.43600356578826904, 테스트 정확도: 92.9560317993164\n",
            "에포크: 400, 손실: 0.01011525746434927, 정확도: 99.69786071777344, 테스트 손실: 0.44562146067619324, 테스트 정확도: 93.00176239013672\n",
            "에포크: 440, 손실: 0.009197774343192577, 정확도: 99.72526550292969, 테스트 손실: 0.4553956985473633, 테스트 정확도: 93.04792022705078\n",
            "에포크: 480, 손실: 0.008432886563241482, 정확도: 99.74810791015625, 테스트 손실: 0.46503084897994995, 테스트 정확도: 93.08963775634766\n",
            "에포크: 520, 손실: 0.007785447873175144, 정확도: 99.7674560546875, 테스트 손실: 0.4747580885887146, 테스트 정확도: 93.1255874633789\n",
            "에포크: 560, 손실: 0.007230335846543312, 정확도: 99.7840347290039, 테스트 손실: 0.48374801874160767, 테스트 정확도: 93.16484832763672\n",
            "에포크: 600, 손실: 0.006749115418642759, 정확도: 99.79840850830078, 테스트 손실: 0.492080420255661, 테스트 정확도: 93.21295928955078\n",
            "에포크: 640, 손실: 0.006327953655272722, 정확도: 99.81098937988281, 테스트 손실: 0.5012566447257996, 테스트 정확도: 93.27062225341797\n",
            "에포크: 680, 손실: 0.005956267938017845, 정확도: 99.82208251953125, 테스트 손실: 0.5093371272087097, 테스트 정확도: 93.32093811035156\n",
            "에포크: 720, 손실: 0.007357514463365078, 정확도: 99.81218719482422, 테스트 손실: 0.5075134038925171, 테스트 정확도: 93.27909851074219\n",
            "에포크: 760, 손실: 0.006973162293434143, 정확도: 99.82205963134766, 테스트 손실: 0.504265546798706, 테스트 정확도: 93.24810028076172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIHKxT4FSzv1",
        "colab_type": "text"
      },
      "source": [
        "train 정확도 99.8%, 테스트 정확도 93.2%로 준수합니다. 하지만 overfitting이 일어난 것 같으니 dropout기법을 적용하여 test 정확도를 조금 더 올려보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nisTpjADVurd",
        "colab_type": "text"
      },
      "source": [
        "### model2 : dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qe06zr2X_te",
        "colab_type": "text"
      },
      "source": [
        "모델의 overfitting을 방지하기 위해 dropout층을 추가했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy9XE1I0ViT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model): \n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.k = 11     \n",
        "    self.seq = 2    \n",
        "    self.conv1 = Conv2D(32, 3, padding=\"same\")\n",
        "    self.pool1 = MaxPool2D(2, padding=\"same\")\n",
        "    self.conv2 = Conv2D(32, 3, padding='same')\n",
        "    self.pool2 = MaxPool2D(2, padding=\"same\")\n",
        "    self.conv3 = Conv2D(32, 3, padding='same')\n",
        "    self.pool3 = MaxPool2D(2, padding=\"same\")\n",
        "    self.dropout = Dropout(rate=0.5)    # 추가한 부분\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation=\"relu\")\n",
        "    self.d2 = Dense(self.k*self.seq) \n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x) \n",
        "    x = self.pool1(x)  \n",
        "    x = self.dropout(x)  # 추가한 부분\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool2(x) \n",
        "    x = self.dropout(x)   # 추가한 부분\n",
        "    x = self.conv3(x)\n",
        "    x = self.pool3(x)  \n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.dropout(x)   # 추가한 부분\n",
        "    h = self.d2(x) \n",
        "    h = tf.reshape(h, [-1, self.seq, self.k])\n",
        "    h = tf.nn.softmax(h, axis=2)   \n",
        "    return h\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8HehVe7WAn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"train_acc\")\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"test_acc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcPV2rOaWAq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  y_hot = tf.one_hot(labels, depth=11, axis=-1)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images) # (m, 8, 16, 1)\n",
        "    loss = loss_object(y_hot, predictions)\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(y_hot, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-VbCPYVWAts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  y_hot = tf.one_hot(labels, depth=11, axis=-1)\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(y_hot, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(y_hot, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBMv9gTqWAxc",
        "colab_type": "code",
        "outputId": "43949973-e7f0-4f03-ceba-fa8b52b6b5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "EPOCHS = 800\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds: # batch size = 32씩 나눠져 들어갑니다\n",
        "    train_step(images, labels)\n",
        "  \n",
        "  for test_images, labels in test_ds:\n",
        "    test_step(test_images, labels)\n",
        "  \n",
        "  template = \"에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}\"\n",
        "  \n",
        "  if epoch%40==0:\n",
        "    print(template.format(epoch,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result()*100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer my_model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "에포크: 0, 손실: 1.691123127937317, 정확도: 42.093544006347656, 테스트 손실: 1.3450655937194824, 테스트 정확도: 58.57461166381836\n",
            "에포크: 40, 손실: 0.09106644988059998, 정확도: 97.2812271118164, 테스트 손실: 0.3153878152370453, 테스트 정확도: 91.75267791748047\n",
            "에포크: 80, 손실: 0.04617966338992119, 정확도: 98.62383270263672, 테스트 손실: 0.30044013261795044, 테스트 정확도: 92.94316864013672\n",
            "에포크: 120, 손실: 0.03092942200601101, 정확도: 99.07876586914062, 테스트 손실: 0.30383631587028503, 테스트 정확도: 93.38520812988281\n",
            "에포크: 160, 손실: 0.023249594494700432, 정확도: 99.3076400756836, 테스트 손실: 0.30945277214050293, 테스트 정확도: 93.6401138305664\n",
            "에포크: 200, 손실: 0.018624380230903625, 정확도: 99.44541931152344, 테스트 손실: 0.31619301438331604, 테스트 정확도: 93.81987762451172\n",
            "에포크: 240, 손실: 0.01553366519510746, 정확도: 99.53746795654297, 테스트 손실: 0.32436931133270264, 테스트 정확도: 93.93719482421875\n",
            "에포크: 280, 손실: 0.013322476297616959, 정확도: 99.60330963134766, 테스트 손실: 0.332393616437912, 테스트 정확도: 94.0179443359375\n",
            "에포크: 320, 손실: 0.011662356555461884, 정확도: 99.65274047851562, 테스트 손실: 0.3421171009540558, 테스트 정확도: 94.07180786132812\n",
            "에포크: 360, 손실: 0.01037012878805399, 정확도: 99.69121551513672, 테스트 손실: 0.35099971294403076, 테스트 정확도: 94.11109924316406\n",
            "에포크: 400, 손실: 0.009335702285170555, 정확도: 99.7220230102539, 테스트 손실: 0.35874703526496887, 테스트 정확도: 94.14034271240234\n",
            "에포크: 440, 손실: 0.008488926105201244, 정확도: 99.74723815917969, 테스트 손실: 0.3660822808742523, 테스트 정확도: 94.16667938232422\n",
            "에포크: 480, 손실: 0.007782986853271723, 정확도: 99.76824951171875, 테스트 손실: 0.37360113859176636, 테스트 정확도: 94.19002532958984\n",
            "에포크: 520, 손실: 0.007185444235801697, 정확도: 99.78604888916016, 테스트 손실: 0.38086622953414917, 테스트 정확도: 94.2135238647461\n",
            "에포크: 560, 손실: 0.006673113442957401, 정확도: 99.80130004882812, 테스트 손실: 0.3885599374771118, 테스트 정확도: 94.23486328125\n",
            "에포크: 600, 손실: 0.0062289792113006115, 정확도: 99.81452941894531, 테스트 손실: 0.39526209235191345, 테스트 정확도: 94.2527084350586\n",
            "에포크: 640, 손실: 0.005840275436639786, 정확도: 99.82609558105469, 테스트 손실: 0.4019129276275635, 테스트 정확도: 94.26737976074219\n",
            "에포크: 680, 손실: 0.005497234407812357, 정확도: 99.83631134033203, 테스트 손실: 0.4071006178855896, 테스트 정확도: 94.27713012695312\n",
            "에포크: 720, 손실: 0.006392054725438356, 정확도: 99.8314208984375, 테스트 손실: 0.4118784964084625, 테스트 정확도: 94.20355987548828\n",
            "에포크: 760, 손실: 0.006058721803128719, 정확도: 99.84027862548828, 테스트 손실: 0.41369691491127014, 테스트 정확도: 94.12287139892578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVhIOsjJXCM3",
        "colab_type": "text"
      },
      "source": [
        "dropout을 cnn층 중간중간에 추가했더니 train 정확도는 99.8%로 거의 변화하지 않았지만 test 정확도는 94.12%로 올랐습니다! 직접 커스터마이징한 모델이 Sequential 모델만큼 잘 작동하는 것 같습니다."
      ]
    }
  ]
}